node_lines:
- node_line_name: retrieve_node_line
  nodes:
    - node_type: retrieval
      strategy:
        metrics: [retrieval_f1, retrieval_ndcg, retrieval_map]
      top_k: 3
      modules:
        - module_type: bm25
        - module_type: vectordb
          embedding_model: openai
        - module_type: hybrid_rrf
          target_modules: ('bm25', 'vectordb')
          rrf_k: [ 3, 5, 10 ]
        - module_type: hybrid_cc
          target_modules: ('bm25', 'vectordb')
          weights:
            - (0.5, 0.5)
            - (0.3, 0.7)
            - (0.7, 0.3)
        - module_type: hybrid_rsf
          target_modules: ('bm25', 'vectordb')
          weights:
            - (0.5, 0.5)
            - (0.3, 0.7)
            - (0.7, 0.3)
        - module_type: hybrid_dbsf
          target_modules: ('bm25', 'vectordb')
          weights:
            - (0.5, 0.5)
            - (0.3, 0.7)
            - (0.7, 0.3)
- node_line_name: post_retrieve_node_line
  nodes:
    - node_type: prompt_maker
      strategy:
        metrics:
          - metric_name: meteor
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: openai
      modules:
        - module_type: fstring
          prompt:
          - | 
            Read the passages and answer the given question. \n Question: {query} \n Passage: {retrieved_contents} \n Answer :
          - |
            Read the passages and answer the given question. Think step by step. \n Question: {query} \n Passage: {retrieved_contents} \n Answer :
    - node_type: generator
      strategy:
        metrics:
          - metric_name: meteor
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: openai
      modules:
        - module_type: openai_llm
          llm: gpt-3.5-turbo
          temperature: [ 0.1, 1.0 ]
          batch: 4
